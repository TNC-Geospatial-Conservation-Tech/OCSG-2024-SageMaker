{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "081f5f70-9273-4fb2-89fe-8fa508b70608",
   "metadata": {},
   "source": [
    "# Introduction to CMIP6 Data\n",
    "\n",
    "**Coupled Model Intercomparison Project Phase 6 (CMIP6)** provides climate model outputs to assess global warming and associated impacts. In this lesson, we will explore the `tas` (2-m near-surface air temperature) variable, and look at its historical trends and future projections. Specifically, we will calculate when each cmip6 model (historical + ssp) reaches a given warming level\n",
    "\n",
    "# Why are we doing this?\n",
    "The Intergovernmental Panel on Climate Change (IPCC) and the US National Climate Assessment (NCA) are moving towards assessing climate impacts at global warming thresholds instead of using a specific emissions pathway because it is highly uncertain which future emissions pathway we will follow (dependent on societal choices, policies, international agreements, etc.). Here you can see for yourself how much the globe has already warmed using NOAA observation-based gridded temperature data and also how we can go about calculating when each climate model used in the lates IPCC report (IPCC AR6) reaches various global warming thresholds relative to the pre-industrial time period (1850-1899)\n",
    "\n",
    "## What you'll learn:\n",
    "1. How to access publicly available data (e.g., from NOAA) and load on AWS\n",
    "2. How to load CMIP6 datasets publicly available on AWS using `intake`.\n",
    "3. How to create annual mean, area-weighted, global-mean air temperature time series from observations and CMIP6 data\n",
    "4. Calculate when each CMIP6 model (in the historical and ssp585 experiments) reaches various global warming thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76236853-00c2-4fbc-8f16-05c20305d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages needed for loading data, etc.\n",
    "%matplotlib inline\n",
    "import xarray as xr #for loading spatial data\n",
    "import pandas as pd #for dealing with saving csv files, etc.\n",
    "import numpy as np #for doing simple math operations\n",
    "from scipy import signal #for smoothing data\n",
    "\n",
    "#matplotlib is for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "#seaborn for fancier plotting (PDFs, violin plots, etc.)\n",
    "import seaborn as sns\n",
    "\n",
    "#the following three are for accessing data on a webite outside AWS\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#for accessing climate model data on AWS\n",
    "import intake\n",
    "\n",
    "#hide warnings to clean up notebook output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454cb4e2-bc60-431c-bb40-209f513f6768",
   "metadata": {},
   "source": [
    "## let's first download a dataset from NOAA of global near-surface air temperatures to look at what the observations have to say about global temperature changes related to the pre-industrial time period (1850-1899)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af2f84a-5425-476a-ae0c-72ae447794c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the directory where NOAA Global Surface Temperature data is hosted\n",
    "base_url = \"https://www.ncei.noaa.gov/data/noaa-global-surface-temperature/v6/access/gridded/\"\n",
    "\n",
    "# Step 1: Scrape the webpage to find the NetCDF (.nc) file link\n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find all links that end with '.nc' -- we want to load the nc file\n",
    "nc_file = None\n",
    "for link in soup.find_all('a'):\n",
    "    href = link.get('href')\n",
    "    if href and href.endswith('.nc'):\n",
    "        nc_file = href\n",
    "        break\n",
    "\n",
    "if nc_file:\n",
    "    print(f\"Found NetCDF file: {nc_file}\")\n",
    "    \n",
    "    # Full URL to the NetCDF file\n",
    "    nc_url = base_url + nc_file\n",
    "    \n",
    "    # Step 2: Download the NetCDF file\n",
    "    filename = nc_file.split('/')[-1]\n",
    "    print(f\"Downloading file: {filename}\")\n",
    "    \n",
    "    # Download the file\n",
    "    nc_response = requests.get(nc_url)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(nc_response.content)\n",
    "\n",
    "    print(f\"File saved as {filename}\")\n",
    "\n",
    "    # Step 3: Load the file using xarray\n",
    "    ds = xr.open_dataset(filename)\n",
    "\n",
    "else:\n",
    "    print(\"No NetCDF file found in the directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf63440-f96d-4f6a-b473-f467ee283f82",
   "metadata": {},
   "source": [
    "## let's look at the noaa dataset and calculate global-mean temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a41a0f1-5dbc-4ac5-b75f-70ea638fe23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046251e9-bc90-47b4-9601-bb8dc6c30b27",
   "metadata": {},
   "source": [
    "## let's plot one time step to look at the data\n",
    "### note the globe is stretched onto a regularly spaced latitude/longitude grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d610dd3-1a88-4c04-a340-6b65fc73883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['anom'].sel(time='2024-08-01').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f39df43-b554-4d3b-85e6-768f0d715d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the variable 'anom' out of the dataset\n",
    "da = ds['anom']\n",
    "\n",
    "# group monthly data into annual-mean time series\n",
    "da_ann = da.groupby('time.year').mean('time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd22d1-d89d-4cf5-808b-6ca65112a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's plot annual mean temperature anomalies in 2023\n",
    "da_ann.sel(year=2023).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5cb9c7-eaf7-4f22-8fbb-3579d3c948f3",
   "metadata": {},
   "source": [
    "## let's look at what happens if we area-weight and don't area-weight gridded data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96ffd8-9a03-44ba-9a4c-86f8ef52b4b2",
   "metadata": {},
   "source": [
    "## first let's take a simple average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d324809-44d5-46cf-b277-12023c826b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first just create a simple average, equally weighting all grid points on globe\n",
    "gmt2m_unweighted = da_ann.mean(dim=('lon','lat'))\n",
    "\n",
    "gmt2m_unweighted.plot()\n",
    "\n",
    "#note temperature anomalies are relative to a late 20th century baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afad5e1c-9d1c-4af7-80fe-1c7b841b736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to examine how much temperature has changed since the pre-industrial, so let's calculate anomalies from this time period\n",
    "gmt2m_unweighted_anom_noaa = (gmt2m_unweighted - gmt2m_unweighted.sel(year=slice(1850,1899)).mean(dim='year'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35080f82-df43-4d77-94e5-5e0ec48d12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot time series\n",
    "gmt2m_unweighted_anom_noaa.plot(color='darkred',label='Unweighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ead003-388a-4373-b544-3df494bb6961",
   "metadata": {},
   "source": [
    "# now create an area-weighted time series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a7aab-12b7-4c86-8619-9f4edccbb9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight for global mean\n",
    "w = np.cos(np.deg2rad(da_ann.lat)) #we are going to area-weight by the cosine of the latitude (as we approach poles, data more and more stretched onto grid)\n",
    "w.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a455c3-b762-46ce-990b-f55b88c4bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w.broadcast_like(da_ann) #broadcast the weighting across all longitudes and time\n",
    "w.sel(year=1850).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e236d79-7b7e-426c-9c0e-be8806a9c162",
   "metadata": {},
   "source": [
    "# use these maps of weights to area-weight temperature anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5f7f2-85e4-4595-b36b-39c19d4bc9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can have some missing data, so let's pull out and area-weight the temperature anomalies where no missing data\n",
    "gmt2m = (w.where(da_ann.notnull()) * da_ann).sum(dim=('lon','lat')) / w.where(da_ann.notnull()).sum(dim=('lon','lat'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff703b-e1c4-4157-b1bc-686ac7152b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to examine how much temperature has changed since the pre-industrial, so let's calculate anomalies from this time period\n",
    "gmt2m_anom_noaa = (gmt2m - gmt2m.sel(year=slice(1850,1899)).mean(dim='year')).sel(year=slice(1850,2099))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6fa0d-7d96-4655-9546-11c1b0e2e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bothtime series\n",
    "gmt2m_unweighted_anom_noaa.plot(color='red',label='Simple Average')\n",
    "gmt2m_anom_noaa.plot(color='black',label='Area-Weighted')\n",
    "#show legend\n",
    "plt.legend()\n",
    "plt.ylabel('Temperature Change from Pre-Industrial ($^o$C)')\n",
    "plt.title('NOAA GlobalTemp Unweighted and Area-Weighted \\n Global-Mean, Near-Surface Temperature Anomalies')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b549a388-1016-4a90-b38b-1ff9f10c2960",
   "metadata": {},
   "source": [
    "## now let's load the climate model (cmip6) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe365a7-7880-4c33-9d76-89eddf5dca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where catalog is\n",
    "catalog_url = \"https://cmip6-pds.s3.amazonaws.com/pangeo-cmip6.json\"  # CMIP6 catalog URL on AWS\n",
    "col = intake.open_esm_datastore(catalog_url)  # Open the CMIP6 catalog using Intake-ESM\n",
    "\n",
    "#pick which ssp we want to load below\n",
    "#we are going with ssp585 because it's a high-emissions pathway and we want to examine impacts at warming levels including 3C\n",
    "#under a lower emissions pathway, like ssp245, some climate models may not reach 3C before 2100\n",
    "ssp = 'ssp585' \n",
    "\n",
    "# Define our query for filtering the data\n",
    "query = dict(\n",
    "    variable_id=[\"tas\"],  # Select surface air temperature\n",
    "    experiment_id=[\"historical\", ssp],  # Select historical and future ssp (e.g., ssp245, ssp585)\n",
    "    table_id=[\"Amon\"],  # Monthly atmospheric data\n",
    "    member_id = [\"r1i1p1f1\"],)  # Specific ensemble member\n",
    "    #source_id=[\"ACCESS-CM2\"])  # Specify the model\n",
    "\n",
    "col_subset = col.search(**query)  # Search and filter the catalog based on the query\n",
    "\n",
    "# Group and display relevant columns to inspect results\n",
    "col_subset.df.groupby(\"source_id\")[[\"experiment_id\", \"variable_id\", \"table_id\"]]\n",
    "\n",
    "col_subset = col_subset.search(require_all_on=[\"source_id\"], **query)  # Further refine the search to ensure all criteria match\n",
    "col_subset.df.groupby(\"source_id\")[[\"experiment_id\", \"variable_id\", \"table_id\"]]  # Re-check the filtered results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250349d-b067-40a4-b79e-88535de69e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include historical data for the \"tas\" variable\n",
    "col_subset_historical = col_subset.search(variable_id=[\"tas\"], experiment_id=[\"historical\"])\n",
    "col_subset_historical.df.sort_values(\"source_id\")  # Sort the results by source_id\n",
    "\n",
    "# Filter to only include ssp data in another dictionary for the \"tas\" variable\n",
    "col_subset_ssp = col_subset.search(variable_id=[\"tas\"],experiment_id=[ssp])\n",
    "col_subset_ssp.df.sort_values(\"source_id\")\n",
    "\n",
    "#define anonymous access\n",
    "storage_options = {\"anon\": True}\n",
    "\n",
    "datasets_historical = col_subset_historical.to_dataset_dict(cdf_kwargs={},storage_options=storage_options)  # Convert the filtered results into xarray datasets\n",
    "datasets_ssp = col_subset_ssp.to_dataset_dict(cdf_kwargs={},storage_options=storage_options)\n",
    "\n",
    "#uncomment next line to display the dataframe\n",
    "#col_subset_historical.df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b415b198-0648-41d0-98ed-b8480eaea439",
   "metadata": {},
   "source": [
    "## now we are going to loop through each climate model and load the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f007b9e4-0db1-4d91-a80d-ccfed15dee71",
   "metadata": {},
   "source": [
    "### before we do that, let's load ONE CMIP6 model and take a look at what the loop is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84f447-173f-4243-85fc-39aec7694a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through the loop without loading the data to see how it works\n",
    "\n",
    "for hii, hi in enumerate(datasets_historical):  # Loop through historical datasets, hii is the index, hi is the dataset key\n",
    "    \n",
    "    ds_historical = datasets_historical[hi]  # Get the historical dataset for the current model\n",
    "    \n",
    "    for sii, si in enumerate(datasets_ssp):  # Nested loop through ssp datasets, sii is the index, si is the dataset key\n",
    "        \n",
    "        ds_ssp = datasets_ssp[si]  # Get the ssp dataset for the current model\n",
    "        \n",
    "        if ds_ssp.attrs['source_id'] == ds_historical.attrs['source_id']:  # Match datasets by model (source_id)\n",
    "\n",
    "            break\n",
    "            \n",
    "da_historical = ds_historical['tas']\n",
    "\n",
    "da_ssp = ds_ssp['tas']\n",
    "\n",
    "print('loading data for both experiments from:', ds_historical.attrs['source_id'],ds_ssp.attrs['source_id'])  # Inform which model is being processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905e5b2-ee4a-40d3-b955-62f7ac69745b",
   "metadata": {},
   "source": [
    "# let's look at the historical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b85d86-5ebe-4267-b46f-327b659c205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_historical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c9f0a6-4325-4bad-8502-6ef3f5297ad8",
   "metadata": {},
   "source": [
    "# let's also look at the ssp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39bd63-71a2-443c-be60-a1b87203d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ssp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e35a43-0c21-4173-88b1-f9c6d40c90fe",
   "metadata": {},
   "source": [
    "## notice we can take out a data array ('tas' variable) from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c2a0b9-b058-49f1-911e-9e3eedc70abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_historical = ds_historical['tas']\n",
    "\n",
    "da_historical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc8eb6-fce3-458b-8667-11665ed370bd",
   "metadata": {},
   "source": [
    "## let's make a map of the last time slice in the historical to see what it looks like:\n",
    "#### note that the 'historical' experiment/runs span 1850-2014\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d3d4a-5ee9-4c41-922d-a3d5cec1310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_historical.isel(time=-1).plot()\n",
    "\n",
    "#note units are in Kelvin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ba249-e8fa-46db-87a4-cf8f52610af2",
   "metadata": {},
   "source": [
    "# let's do the same for the ssp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb344a-f6ea-4447-9f29-ba41eec7473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_ssp = ds_ssp['tas'] \n",
    "\n",
    "da_ssp.isel(time=-1).plot()\n",
    "\n",
    "#note xarray auto-sets the colorbar limit (it's now 310K!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6395588-7700-4ed3-b805-e6beda480cc5",
   "metadata": {},
   "source": [
    "## since data are in Kelvin, let's convert to Celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb4bac9-b9c5-494b-b364-320110d84c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert historical 'tas' (temperature) from Kelvin to Celsius\n",
    "da_historical = (ds_historical['tas'] - 273.15)\n",
    "\n",
    "da_ssp = (ds_ssp['tas'] - 273.15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e994f-54b6-4755-9c40-e025d8f416f5",
   "metadata": {},
   "source": [
    "## now we are going to annualize the monthly data\n",
    "### note that some climate modeling groups may save the temporal range of output in a non-standard way, so we are going to specify the time slice we want to load: 1850-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791240b2-b71a-435a-8df4-e46be4a12baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annual mean temperature for historical data (1850-2014)\n",
    "da_historical_ann = da_historical.groupby('time.year').mean('time').sel(year=slice(1850, 2014))\n",
    "\n",
    "#same for the ssp, but for 2015-2100\n",
    "da_ssp_ann = da_ssp.groupby('time.year').mean('time').sel(year=slice(2015, 2100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0821976-7798-4372-9a29-5cd31c163820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the historical and ssp data along the 'year' dimension\n",
    "da_historical_ssp_ann = xr.concat((da_historical_ann, da_ssp_ann), dim='year')\n",
    "\n",
    "#note we now have a continuous annual time series: 1850-2100\n",
    "da_historical_ssp_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad23ac7-2c92-44cb-95d6-816e81640630",
   "metadata": {},
   "source": [
    "## now we are going to area-weight by latitude, create global-mean near-surface air temperature time series from maps of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b411c-84cd-47fe-ac83-2708767d22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculate weights based on latitude for global mean (cosine latitude weighting)\n",
    "w = np.cos(np.deg2rad(da_historical_ssp_ann.lat))\n",
    "w = w.broadcast_like(da_historical_ssp_ann)  # Ensure weights have the same shape as the data\n",
    "\n",
    "# Calculate global mean temperature using area weights (latitude weighted average)\n",
    "gmt2m = ((w * da_historical_ssp_ann).sum(dim=('lon', 'lat')) / w.sum(dim=('lon', 'lat'))).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe40dd-c9fe-4048-801d-0a3c6f34d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmt2m.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dc215e-3534-46f4-8206-c4987a71926f",
   "metadata": {},
   "source": [
    "## loop through and load each climate model- doing the same as above and saving the output at the end of the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada97fd8-59c9-4637-aefe-e45d415f19d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#time how long it takes to loop through all CMIP6 models defined above\n",
    "\n",
    "#empty list to be filled with each model name\n",
    "cmip6_models = []\n",
    "\n",
    "for hii, hi in enumerate(datasets_historical):  # Loop through historical datasets, hii is the index, hi is the dataset key\n",
    "    \n",
    "    ds_historical = datasets_historical[hi]  # Get the historical dataset for the current model\n",
    "    \n",
    "    for sii, si in enumerate(datasets_ssp):  # Nested loop through ssp datasets, sii is the index, si is the dataset key\n",
    "        \n",
    "        ds_ssp = datasets_ssp[si]  # Get the ssp dataset for the current model\n",
    "        \n",
    "        if ds_ssp.attrs['source_id'] == ds_historical.attrs['source_id']:  # Match datasets by model (source_id)\n",
    "            \n",
    "            print('loading data for both experiments from:', ds_ssp.attrs['source_id'])  # Inform which model is being processed\n",
    "\n",
    "            #append this model's name to list\n",
    "            cmip6_models.append(ds_ssp.attrs['source_id'])\n",
    "            \n",
    "            # Convert historical 'tas' (temperature) from Kelvin to Celsius\n",
    "            da_historical = (ds_historical['tas'] - 273.15)\n",
    "            \n",
    "            # Calculate the annual mean temperature for historical data (1850-2014)\n",
    "            da_historical_ann = da_historical.groupby('time.year').mean('time').sel(year=slice(1850, 2014))\n",
    "            \n",
    "            # Convert ssp 'tas' (temperature) from Kelvin to Celsius\n",
    "            da_ssp = ds_ssp['tas'] - 273.15\n",
    "            \n",
    "            # Calculate the annual mean temperature for ssp data (2015-2100)\n",
    "            da_ssp_ann = da_ssp.groupby('time.year').mean('time').sel(year=slice(2015, 2100))\n",
    "\n",
    "            # Concatenate the historical and ssp data along the 'year' dimension\n",
    "            da_historical_ssp_ann = xr.concat((da_historical_ann, da_ssp_ann), dim='year')\n",
    "            \n",
    "            # Calculate weights based on latitude for global mean (cosine latitude weighting)\n",
    "            w = np.cos(np.deg2rad(da_historical_ssp_ann.lat))\n",
    "            w = w.broadcast_like(da_historical_ssp_ann)  # Ensure weights have the same shape as the data\n",
    "            \n",
    "            # Calculate global mean temperature using area weights (latitude weighted average)\n",
    "            gmt2m = ((w * da_historical_ssp_ann).sum(dim=('lon', 'lat')) / w.sum(dim=('lon', 'lat'))).compute()\n",
    "            \n",
    "            if hii == 0:  # For the first iteration, initialize the global mean temperature (gmt) collection\n",
    "                cmip6_gmtm = gmt2m\n",
    "            else:\n",
    "                # For subsequent iterations, concatenate the global mean temperature data along the 'model' dimension\n",
    "                cmip6_gmtm = xr.concat((cmip6_gmtm, gmt2m), dim='model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0086d1f-84db-49cf-9682-eec8f67c4701",
   "metadata": {},
   "source": [
    "## compute anomalies (changes) from pre-industrial time period (typically defined as ~1850-1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17920c76-f403-4c14-b582-5dd220fa779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmip6_gmtm_anom = (\n",
    "    cmip6_gmtm \n",
    "    - cmip6_gmtm.sel(year=slice(1850,1899)).mean(dim='year')\n",
    ").sel(year=slice(1850,2100)).compute()  # Calculate temperature anomalies relative to the 1850-1899 mean, select data for 1850-2100, and compute\n",
    "\n",
    "cmip6_gmtm_anom = cmip6_gmtm_anom.squeeze()  # Remove any singleton dimensions from the data (e.g., a dimension of size 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47af091-311a-4282-aa1f-34e8d27771dc",
   "metadata": {},
   "source": [
    "## take a quick look at the data in a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1b750-7c36-424b-918d-a4521f2c2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through each climade model, plot \n",
    "for mi,model in enumerate(cmip6_models):\n",
    "    cmip6_gmtm_anom.sel(model=mi).plot()\n",
    "    \n",
    "#plot noaa temperature anomalies on top of climate model data\n",
    "gmt2m_anom_noaa.plot(color='black')\n",
    "\n",
    "#make title for graph\n",
    "plt.title('CMIP6 hist+'+str(ssp)+' NOAA GlobalTemp Global-Mean tas anomalies')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5c93a-b77c-4c30-b199-c57c1d01c346",
   "metadata": {},
   "source": [
    "## calculate when global-mean temperature anomalies cross temperature thresholds in annual and 20-year smoothed data\n",
    "#### note that we are looking at when a 20-year rolling average and annual averages cross certain warming thresholds- we will see later that due to interannual climate variability, we can cross a thresold like 1C or 1.5C for a year, then re-cross it later- according to the IPCC, we should be interested in when global temperatures consistently cross these thresholds- usually we can assess this using a rolling average of 20 or 30 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435a557-1ccd-4fda-b267-e5008a51c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_ave_window = 20  # Set the window size for the rolling average (20 years)\n",
    "temps = [1, 1.5, 2, 2.5, 3]  # List of temperature thresholds (in degrees Celsius) to analyze\n",
    "\n",
    "for ti, temp in enumerate(temps):  # Loop through each temperature threshold\n",
    "    \n",
    "    print('assessing when each climate model reaches',temp,'C Global Warming Threshold')\n",
    "    \n",
    "    # Initialize empty lists for storing years when temperature thresholds are reached\n",
    "    vars()['firstyear_rolling_' + str(temp) + 'C'] = []\n",
    "    \n",
    "    for mi, model in enumerate(cmip6_models):  # Loop through each model in the ssp dataset\n",
    "        \n",
    "        # Select annual data for the current model\n",
    "        annual = cmip6_gmtm_anom.sel(model=mi)\n",
    "        \n",
    "        # Calculate the rolling average (20-year window) for annual data\n",
    "        smoothed = annual.rolling(year=rolling_ave_window, center=True).mean()\n",
    "        \n",
    "        # Find the first year where the rolling mean matches the temperature threshold\n",
    "        year_temp_smoothed = (smoothed.year.where(smoothed >= temp, drop=True)).year.min().item()\n",
    "        \n",
    "        # Append to the rolling average list\n",
    "        vars()['firstyear_rolling_' + str(temp) + 'C'].append(year_temp_smoothed)  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230023c0-a23f-46b2-95f0-77407b082492",
   "metadata": {},
   "source": [
    "## save when each model crosses the global warming threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408541a3-fcb8-42cd-8e50-83876bbb1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all data together in a numpy array\n",
    "all_temps_rolling = np.vstack((\n",
    "    np.array(vars()['firstyear_rolling_'+str(1)+'C']),\n",
    "    np.array(vars()['firstyear_rolling_'+str(1.5)+'C']),\n",
    "    np.array(vars()['firstyear_rolling_'+str(2)+'C']),\n",
    "    np.array(vars()['firstyear_rolling_'+str(2.5)+'C']),\n",
    "    np.array(vars()['firstyear_rolling_'+str(3)+'C']),\n",
    "                      )\n",
    "                     ).T\n",
    "\n",
    "#use pandas to save as a data frame\n",
    "cmip6_models_warminglevels_df_rolling = pd.DataFrame(data=(all_temps_rolling),\n",
    "             index=cmip6_models,\n",
    "            columns=temps)  # 1st row as the column names\n",
    "\n",
    "#rename index column as CMIP6 Model\n",
    "cmip6_models_warminglevels_df_rolling.index.name = 'CMIP6 Model'\n",
    "\n",
    "#data are output randomly as they were found on the storage- we want to organize by alphabetical order\n",
    "cmip6_models_warminglevels_df_rolling = cmip6_models_warminglevels_df_rolling.sort_index()\n",
    "\n",
    "#save dataframe as csv file for importing later or downloading\n",
    "cmip6_models_warminglevels_df_rolling.to_csv('CMIP6_nModels_'+str(len(cmip6_models))+'_GWLevels_'+str(ssp)+'_Smoothed_FirstYearThreshold.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d09eb-45d0-49a3-8ff5-5aaabc7c2376",
   "metadata": {},
   "source": [
    "## print when reach 2C global warming in this ssp, and then \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4fbc1-579a-4383-b0e5-568e6ca01137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a global warming threshold of 2C\n",
    "temp = 2\n",
    "\n",
    "print('Rolling method median:',np.median(np.array(vars()['firstyear_rolling_'+str(temp)+'C'])))\n",
    "print('Rolling method 5th percentile:',np.quantile(np.array(vars()['firstyear_rolling_'+str(temp)+'C']),0.05))\n",
    "print('Rolling method 95th percentile:',np.quantile(np.array(vars()['firstyear_rolling_'+str(temp)+'C']),0.95))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8492b63-137a-4994-a36e-b54f50dff58c",
   "metadata": {},
   "source": [
    "## make a PDF of this distribution when the models hit 2C warming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404370d4-235a-449a-ada1-7511907b6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot PDF of when reach these thresholds using seaborn\n",
    "sns.kdeplot(np.array(vars()['firstyear_rolling_'+str(temp)+'C']),alpha=0.5,fill=True,label='20-Yr Rolling Mean Above')\n",
    "plt.title('CMIP6 Distribution: \\n Timing of Reaching '+str(temp)+'$^o$C Global Warming in '+str(ssp))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Density (-)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230548e-b006-4ef3-b2a6-6ff2f7e61e86",
   "metadata": {},
   "source": [
    "## make line graph of gmtas, and plot dots when each climate model reaches a given warming level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e504b1-c45f-44bf-9d0c-d8af0564386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = cmip6_gmtm_anom.year\n",
    "\n",
    "fsize = 14\n",
    "\n",
    "fig = plt.figure(figsize=(8,6)) #set figure size\n",
    "\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "#we are going to create a shaded error bar region showing the spread in climate model data\n",
    "plt.fill_between(time,\n",
    "                 cmip6_gmtm_anom.rolling(year=rolling_ave_window, center=True).mean().max(dim='model'),\n",
    "                 cmip6_gmtm_anom.rolling(year=rolling_ave_window, center=True).mean().min(dim='model'),\n",
    "                 color='darkred',\n",
    "                alpha=0.5) #alpha is opacity of the shading\n",
    "\n",
    "# let's also create a line showing the multi-model median\n",
    "plt.plot(time,\n",
    "         cmip6_gmtm_anom.rolling(year=rolling_ave_window, center=True).mean().median(dim='model'),\n",
    "         color='darkred',\n",
    "        label='Historical + '+str(ssp))\n",
    "\n",
    "#now let's add dots on the shaded area showing where each climate model hits the warming threshold\n",
    "for ti,temp in enumerate(temps):\n",
    "    for mi,model in enumerate(cmip6_models):\n",
    "        plt.scatter(vars()['firstyear_rolling_'+str(temp)+'C'][mi],temp)\n",
    "\n",
    "#for fun, let's plot the NOAA observation based data on top\n",
    "gmt2m_anom_noaa.rolling(year=rolling_ave_window, center=True).mean().plot(color='black',label='NOAA GlobalTemp')\n",
    "\n",
    "plt.xlim(1860,2090)\n",
    "plt.ylim(-0.5,6)\n",
    "plt.grid()\n",
    "plt.axhline(0, color='black', linestyle=':',linewidth=2,label=('1850-1899 Average'))\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.xlabel('Year',fontsize=fsize)\n",
    "plt.ylabel('Global-Mean Temperature Change ($^o$C)',fontsize=fsize)\n",
    "plt.legend(loc='upper left',fontsize=fsize)\n",
    "plt.title('CMIP6 Global-Mean Temperature Change \\n Relative to 19th Century (Rolling 20yr Ave, '+str(ssp)+')',fontsize=fsize)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74a5d24-394f-4457-be2d-6ea9e972f8e7",
   "metadata": {},
   "source": [
    "## plot the same, but for annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed27fd3-5e78-49ca-9c93-81d707f9dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = cmip6_gmtm_anom.year\n",
    "\n",
    "fsize = 14\n",
    "\n",
    "fig = plt.figure(figsize=(8,6)) #set figure size\n",
    "\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "plt.fill_between(time,\n",
    "                 cmip6_gmtm_anom.max(dim='model'),\n",
    "                 cmip6_gmtm_anom.min(dim='model'),\n",
    "                 color='darkred',\n",
    "                alpha=0.5)\n",
    "plt.plot(time,\n",
    "         cmip6_gmtm_anom.median(dim='model'),\n",
    "         color='darkred',\n",
    "        label='Historical + '+str(ssp))\n",
    "\n",
    "gmt2m_anom_noaa.plot(color='black',label='NOAA GlobalTemp')\n",
    "\n",
    "plt.xlim(1850,2099)\n",
    "plt.ylim(-0.5,6)\n",
    "plt.grid()\n",
    "plt.axhline(0, color='black', linestyle=':',linewidth=2,label=('1850-1899 Average'))\n",
    "plt.xticks(fontsize=fsize)\n",
    "plt.yticks(fontsize=fsize)\n",
    "plt.xlabel('Year',fontsize=fsize)\n",
    "plt.ylabel('Global-Mean Temperature Change ($^o$C)',fontsize=fsize)\n",
    "plt.legend(loc='upper left',fontsize=fsize)\n",
    "plt.title('CMIP6 Global-Mean Temperature Change \\n Relative to 19th Century ('+str(ssp)+')',fontsize=fsize)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a8f78d-cd08-48e9-b973-ff8d3bd2edbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeointake",
   "language": "python",
   "name": "pangeointake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
